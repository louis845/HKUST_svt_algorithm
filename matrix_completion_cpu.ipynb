{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdb0a993",
   "metadata": {},
   "source": [
    "Important: Each sequence of cells separate by large headers (# in markdown) can be run separately\n",
    "Each sequence of cells under the same large header should be run sequentially from top to bottom."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3d2648",
   "metadata": {},
   "source": [
    "# Testing of SVT algorithm with artifical data and given rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "699bf7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import svtcpu\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# compute the performance of the prediction\n",
    "# returns the max error in the given locations, the relative error between the Frobenius norm respect to actual matrix,\n",
    "# and the rank.\n",
    "def compute_performance(actual_matrix, predicted_matrix, locations):\n",
    "    diff = []\n",
    "    for k in range(len(locations[0])):\n",
    "        i=locations[0][k]\n",
    "        j=locations[1][k]\n",
    "        diff.append(abs(actual_matrix[i,j] - predicted_matrix[i,j])) \n",
    "    max_diff = max(diff)\n",
    "\n",
    "    # compute the relative error between the actual matrix and the resultant matrix\n",
    "    rel_error = np.linalg.norm(actual_matrix - predicted_matrix, ord='fro') / np.linalg.norm(actual_matrix, ord='fro')\n",
    "\n",
    "    # compute the rank of the predicted matrix\n",
    "    u,s,v = np.linalg.svd(predicted_matrix)\n",
    "    rank = sum(s>0.001)\n",
    "    return max_diff, rel_error, rank\n",
    "    \n",
    "\n",
    "def bulk_test_small_matrices_given_rank(width, height, fixed_entries_num, rank, method = \"normal\", scale = 1.0, num_trials = 5):\n",
    "    max_errors = []\n",
    "    rel_errors = []\n",
    "    ranks = []\n",
    "    time_elapsed = []\n",
    "    for k in range(num_trials):\n",
    "        # generate a matrix with given rank\n",
    "        actual_M = utils.generate_matrix_rank(width, height, rank, method = method, scale = scale)\n",
    "        # generate random locations (of entries) to pass to the sparse matrix\n",
    "        locations = utils.convert_locations( utils.generate_locations(width, height, fixed_entries_num) )\n",
    "        # with the locations, create a sparse matrix\n",
    "        M = utils.filter_locations(actual_M, locations)\n",
    "        \n",
    "        # using SVT algorithm, predict the original matrix from the sparse matrix\n",
    "        time_svt = time.time()\n",
    "        result = svtcpu.svt_algorithm_auto_params_known_rank(M, locations, rank = rank, log=False)\n",
    "        time_svt = int(time.time()-time_svt)\n",
    "        print(\"time elasped: \", time_svt, \" s\")\n",
    "        \n",
    "        max_diff, rel_error, rank = compute_performance(actual_M, result, locations)\n",
    "        print(\"diff on locations:  \",max_diff,\"relative error:  \",rel_error, \"rank:  \", rank)\n",
    "        max_errors.append(max_diff)\n",
    "        rel_errors.append(rel_error)\n",
    "        ranks.append(rank)\n",
    "        time_elapsed.append(time_svt)\n",
    "        \n",
    "    print(\"average absolute error: \", np.mean(np.array(max_errors)),\" average relative error: \", np.mean(np.array(rel_errors)), \" average time elapsed: \", np.mean(np.array(time_elapsed)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c2b994",
   "metadata": {},
   "source": [
    "## 1000x1000 matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec807086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------Testing 1000x1000------------\n",
      "--------Normal, scale=1.0--------\n",
      "Step size:  10.0     tau:  5000\n",
      "time elasped:  12  s\n",
      "diff on locations:   0.07048942238063322 relative error:   0.00164222095417725 rank:   10\n",
      "Step size:  10.0     tau:  5000\n",
      "time elasped:  12  s\n",
      "diff on locations:   0.03285203443459528 relative error:   0.0015855425863229484 rank:   10\n",
      "Step size:  10.0     tau:  5000\n",
      "time elasped:  13  s\n",
      "diff on locations:   0.06343395797089268 relative error:   0.001641685212990671 rank:   10\n",
      "Step size:  10.0     tau:  5000\n",
      "time elasped:  12  s\n",
      "diff on locations:   0.04533275461455588 relative error:   0.0016406647538154938 rank:   10\n",
      "Step size:  10.0     tau:  5000\n",
      "time elasped:  12  s\n",
      "diff on locations:   0.04934980754568219 relative error:   0.0015896341269456462 rank:   10\n",
      "average absolute error:  0.05229159538927185  average relative error:  0.001619949526850402  average time elapsed:  12.2\n",
      "Step size:  3.076923076923077     tau:  5000\n",
      "time elasped:  50  s\n",
      "diff on locations:   0.04544220502639007 relative error:   0.0015640811388385372 rank:   50\n",
      "Step size:  3.076923076923077     tau:  5000\n",
      "time elasped:  52  s\n",
      "diff on locations:   0.04629869173975143 relative error:   0.001594747350720118 rank:   50\n",
      "Step size:  3.076923076923077     tau:  5000\n",
      "time elasped:  49  s\n",
      "diff on locations:   0.045046585178997844 relative error:   0.0015898441140892393 rank:   50\n",
      "Step size:  3.076923076923077     tau:  5000\n",
      "time elasped:  50  s\n",
      "diff on locations:   0.048984934781238776 relative error:   0.001587696733456143 rank:   50\n",
      "Step size:  3.076923076923077     tau:  5000\n",
      "time elasped:  48  s\n",
      "diff on locations:   0.05971195716760924 relative error:   0.0016167649779721953 rank:   50\n",
      "average absolute error:  0.04909687477879747  average relative error:  0.0015906268630152467  average time elapsed:  49.8\n",
      "Step size:  2.1052631578947367     tau:  5000\n",
      "time elasped:  111  s\n",
      "diff on locations:   0.05469366637354156 relative error:   0.0016453793243215178 rank:   100\n",
      "Step size:  2.1052631578947367     tau:  5000\n",
      "time elasped:  111  s\n",
      "diff on locations:   0.06379690271644822 relative error:   0.0016963377515499492 rank:   100\n",
      "Step size:  2.1052631578947367     tau:  5000\n",
      "time elasped:  112  s\n",
      "diff on locations:   0.06303209626089412 relative error:   0.0016705449341790322 rank:   100\n",
      "Step size:  2.1052631578947367     tau:  5000\n",
      "time elasped:  112  s\n",
      "diff on locations:   0.06671791611558597 relative error:   0.0016864140346052124 rank:   100\n",
      "Step size:  2.1052631578947367     tau:  5000\n",
      "time elasped:  112  s\n",
      "diff on locations:   0.06434256049500675 relative error:   0.0016296238026489596 rank:   100\n",
      "average absolute error:  0.06251662839229533  average relative error:  0.0016656599694609344  average time elapsed:  111.6\n"
     ]
    }
   ],
   "source": [
    "print(\"------------Testing 1000x1000------------\")\n",
    "print(\"--------Normal, scale=1.0--------\")\n",
    "bulk_test_small_matrices_given_rank(1000, 1000, 120000, 10, method = \"normal\", scale = 1.0)\n",
    "bulk_test_small_matrices_given_rank(1000, 1000, 390000, 50, method = \"normal\", scale = 1.0)\n",
    "bulk_test_small_matrices_given_rank(1000, 1000, 570000, 100, method = \"normal\", scale = 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df633ff",
   "metadata": {},
   "source": [
    "## 5000x5000 matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08f1189f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------Testing 5000x5000------------\n",
      "Step size:  50.0     tau:  25000\n",
      "time elasped:  385  s\n",
      "diff on locations:   0.06461660686870552 relative error:   0.001706489698112507 rank:   10\n",
      "Step size:  50.0     tau:  25000\n",
      "time elasped:  400  s\n",
      "diff on locations:   0.07635663327220366 relative error:   0.0016323038530537378 rank:   10\n",
      "Step size:  50.0     tau:  25000\n",
      "time elasped:  376  s\n",
      "diff on locations:   0.06389376401175095 relative error:   0.0016666222630925811 rank:   10\n",
      "Step size:  50.0     tau:  25000\n",
      "time elasped:  394  s\n",
      "diff on locations:   0.08585635191938223 relative error:   0.001669331809080294 rank:   10\n",
      "Step size:  50.0     tau:  25000\n",
      "time elasped:  373  s\n",
      "diff on locations:   0.06356849205868009 relative error:   0.0016406124908615925 rank:   10\n",
      "average absolute error:  0.07085836962614449  average relative error:  0.0016630720228401424  average time elapsed:  385.6\n",
      "Step size:  50.0     tau:  25000\n",
      "time elasped:  1470  s\n",
      "diff on locations:   0.027250450517046332 relative error:   0.0015484972486065635 rank:   10\n",
      "Step size:  50.0     tau:  25000\n",
      "time elasped:  1421  s\n",
      "diff on locations:   0.029151004804178093 relative error:   0.0015396558906068157 rank:   10\n",
      "Step size:  50.0     tau:  25000\n",
      "time elasped:  1444  s\n",
      "diff on locations:   0.02556829668561056 relative error:   0.0015436598056224272 rank:   10\n",
      "Step size:  50.0     tau:  25000\n",
      "time elasped:  1414  s\n",
      "diff on locations:   0.024493190970123813 relative error:   0.0015280313286320634 rank:   10\n",
      "Step size:  50.0     tau:  25000\n",
      "time elasped:  1444  s\n",
      "diff on locations:   0.031109768706909735 relative error:   0.001534216213589726 rank:   10\n",
      "average absolute error:  0.027514542336773706  average relative error:  0.0015388120974115193  average time elapsed:  1438.6\n"
     ]
    }
   ],
   "source": [
    "print(\"------------Testing 5000x5000------------\")\n",
    "bulk_test_small_matrices_given_rank(5000, 5000, 600000, 10, method = \"normal\", scale = 1.0)\n",
    "bulk_test_small_matrices_given_rank(5000, 5000, 600000, 10, method = \"uniform\", scale = 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1277a5fd",
   "metadata": {},
   "source": [
    "# Comparison of SVT algorithm with gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8e142ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import svtcpu\n",
    "import time\n",
    "import numpy as np\n",
    "import descent\n",
    "\n",
    "# same function as above\n",
    "def compute_performance(actual_matrix, predicted_matrix, locations):\n",
    "    diff = []\n",
    "    for k in range(len(locations[0])):\n",
    "        i=locations[0][k]\n",
    "        j=locations[1][k]\n",
    "        diff.append(abs(actual_matrix[i,j] - predicted_matrix[i,j])) \n",
    "    max_diff = max(diff)\n",
    "\n",
    "    # compute the relative error between the actual matrix and the resultant matrix\n",
    "    rel_error = np.linalg.norm(actual_matrix - predicted_matrix, ord='fro') / np.linalg.norm(actual_matrix, ord='fro')\n",
    "\n",
    "    # compute the rank of the resultant matrix\n",
    "    u,s,v = np.linalg.svd(predicted_matrix)\n",
    "    rank = sum(s>0.001)\n",
    "    return max_diff, rel_error, rank\n",
    "\n",
    "# comparison of SVT with gradient descent\n",
    "def bulk_compare_small_matrices_given_rank(width, height, fixed_entries_num, rank, method = \"normal\", scale = 1.0, num_trials = 5):\n",
    "    max_errors_SVT = []\n",
    "    rel_errors_SVT = []\n",
    "    ranks_SVT = []\n",
    "    time_elapsed_SVT = []\n",
    "    \n",
    "    max_errors_descent = []\n",
    "    rel_errors_descent = []\n",
    "    ranks_descent = []\n",
    "    time_elapsed_descent = []\n",
    "    for k in range(num_trials):\n",
    "        # generate a matrix with given rank\n",
    "        actual_M = utils.generate_matrix_rank(width, height, rank, method = method, scale = scale)\n",
    "        # generate random locations (of entries) to pass to the sparse matrix\n",
    "        locations = utils.convert_locations( utils.generate_locations(width, height, fixed_entries_num) )\n",
    "        # with the locations, create a sparse matrix\n",
    "        M = utils.filter_locations(actual_M, locations)\n",
    "        \n",
    "        # using SVT algorithm, predict the original matrix from the sparse matrix\n",
    "        time_svt = time.time()\n",
    "        result = svtcpu.svt_algorithm_auto_params_known_rank(M, locations, rank = rank, log=False, tolerance = 0.01)\n",
    "        time_svt = int(time.time()-time_svt)\n",
    "        print(\"time elasped: \", time_svt, \" s\")\n",
    "        \n",
    "        # compute the absolute difference of values in entries in the locations,\n",
    "        # for the actual matrix and the resultant matrix\n",
    "        max_diff, rel_error, rank = compute_performance(actual_M, result, locations)\n",
    "        \n",
    "        print(\"diff on locations:  \",max_diff,\"relative error:  \",rel_error, \"rank:  \", rank, \"     (SVT)\")\n",
    "        max_errors_SVT.append(max_diff)\n",
    "        rel_errors_SVT.append(rel_error)\n",
    "        ranks_SVT.append(rank)\n",
    "        time_elapsed_SVT.append(time_svt)\n",
    "        \n",
    "        \n",
    "        # using gradient descent, predict the original matrix from the sparse matrix\n",
    "        time_descent = time.time()\n",
    "        result = descent.gradient_descent_completion(M, locations, rank = rank, log=False, tolerance = 0.01)\n",
    "        time_descent = int(time.time()-time_descent)\n",
    "        print(\"time elasped: \", time_descent, \" s\")\n",
    "        \n",
    "        # compute the absolute difference of values in entries in the locations,\n",
    "        # for the actual matrix and the resultant matrix\n",
    "        max_diff, rel_error, rank = compute_performance(actual_M, result, locations)\n",
    "        \n",
    "        print(\"diff on locations:  \",max_diff,\"relative error:  \",rel_error, \"rank:  \", rank, \"     (descent)\")\n",
    "        max_errors_descent.append(max_diff)\n",
    "        rel_errors_descent.append(rel_error)\n",
    "        ranks_descent.append(rank)\n",
    "        time_elapsed_descent.append(time_descent)\n",
    "    print(\"average absolute error: \", np.mean(np.array(max_errors_SVT)),\" average relative error: \", np.mean(np.array(rel_errors_SVT)), \" average time elapsed: \", np.mean(np.array(time_elapsed_SVT)), \"    (SVT)\")\n",
    "    print(\"average absolute error: \", np.mean(np.array(max_errors_descent)),\" average relative error: \", np.mean(np.array(rel_errors_descent)), \" average time elapsed: \", np.mean(np.array(time_elapsed_descent)), \"    (descent)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98650458",
   "metadata": {},
   "source": [
    "## 5000x5000 matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69e8a859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------Testing 5000x5000------------\n",
      "Step size:  50.0     tau:  25000\n",
      "time elasped:  199  s\n",
      "diff on locations:   0.3420094642757965 relative error:   0.016004591936981893 rank:   10      (SVT)\n",
      "torch.Size([5000, 10])\n",
      "torch.Size([5000, 10])\n",
      "time elasped:  1597  s\n",
      "diff on locations:   0.7582143193855684 relative error:   0.016623951228249195 rank:   10      (descent)\n",
      "average absolute error:  0.3420094642757965  average relative error:  0.016004591936981893  average time elapsed:  199.0     (SVT)\n",
      "average absolute error:  0.7582143193855684  average relative error:  0.016623951228249195  average time elapsed:  1597.0     (descent)\n"
     ]
    }
   ],
   "source": [
    "print(\"------------Testing 5000x5000------------\")\n",
    "bulk_compare_small_matrices_given_rank(5000, 5000, 600000, 10, method = \"normal\", scale = 1.0, num_trials = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c16f2f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
